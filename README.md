## generated-videos

Samples of videos generated from 9 model experiments. The final model is experiment: "2D output" named Vid2Pix. All videos contain 4 generated frames. All model experiments besides the last, have been trained using early stopping.


#### Original Pix2Pix
![gif](gifs/gif_0_0.gif) ![gif](gifs/gif_0_1.gif) ![gif](gifs/gif_0_2.gif) ![gif](gifs/gif_0_3.gif) 

#### Replace with 3D layers
![gif](gifs/gif_1_0.gif) ![gif](gifs/gif_1_1.gif) ![gif](gifs/gif_1_2.gif) ![gif](gifs/gif_1_3.gif) 

#### Change filter size
![gif](gifs/gif_2_0.gif) ![gif](gifs/gif_2_1.gif) ![gif](gifs/gif_2_2.gif) ![gif](gifs/gif_2_3.gif) 

#### Offset Downsampling
![gif](gifs/gif_3_0.gif) ![gif](gifs/gif_3_1.gif) ![gif](gifs/gif_3_2.gif) ![gif](gifs/gif_3_3.gif) 

#### Reduce discriminator complexity
![gif](gifs/gif_4_0.gif) ![gif](gifs/gif_4_1.gif) ![gif](gifs/gif_4_2.gif) ![gif](gifs/gif_4_3.gif) 

#### Keep more features
![gif](gifs/gif_5_0.gif) ![gif](gifs/gif_5_1.gif) ![gif](gifs/gif_5_2.gif) ![gif](gifs/gif_5_3.gif) 

#### Add noise
![gif](gifs/gif_6_0.gif) ![gif](gifs/gif_6_1.gif) ![gif](gifs/gif_6_2.gif) ![gif](gifs/gif_6_3.gif) 

#### 2D output Vid2Pix
![gif](gifs/gif_7_0.gif) ![gif](gifs/gif_7_1.gif) ![gif](gifs/gif_7_2.gif) ![gif](gifs/gif_7_3.gif) 

#### 2D output 1000 epochs
![gif](gifs/gif_7_1_0.gif) ![gif](gifs/gif_7_1_1.gif) ![gif](gifs/gif_7_1_2.gif) ![gif](gifs/gif_7_1_3.gif) 
